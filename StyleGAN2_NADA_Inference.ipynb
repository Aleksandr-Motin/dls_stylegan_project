{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# StyleGAN2 + CLIP (StyleGAN-NADA) — Inference Only\n",
        "\n",
        "**Purpose:** Load a trained generator and generate samples. No training.\n",
        "\n",
        "**Flow:** Choose **VERSION** and **EPOCH**. Each checkpoint is in its own Drive folder; we download only that folder. Local layout: `checkpoints/v1/50/checkpoint_50.pt`, `checkpoints/v1/200/checkpoint_200.pt`, etc. StyleGAN2 code from GitHub."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## User settings\n",
        "\n",
        "Choose **VERSION** and **EPOCH** of the checkpoint to load. Epochs: 50, 100, 150, 200, 250, 300."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Checkpoint folder (one per version) + download\n",
        "\n",
        "Paste a **direct download link** for each checkpoint (version, epoch). Use Google Drive “Get link” → “Anyone with the link” and paste the link or the `https://drive.google.com/uc?id=FILE_ID` URL. Then run the cell below to download the chosen checkpoint if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "# One folder link per (version, epoch). Each folder contains one file: checkpoint_EPOCH.pt\n",
        "# Structure: checkpoints/VERSION/EPOCH/checkpoint_EPOCH.pt\n",
        "CHECKPOINT_FOLDER_LINKS = {\n",
        "    \"1\": {\n",
        "        50: \"https://drive.google.com/drive/folders/1MvSVn62B_Hz21V3-5cTFktSB-CY-toma?usp=drive_link\",\n",
        "        100: \"https://drive.google.com/drive/folders/1omeDE_8Anl9IjV-JzRN4es_h_S5ECh-R?usp=drive_link\",\n",
        "        150: \"https://drive.google.com/drive/folders/PASTE_FOLDER_ID\",\n",
        "        200: \"https://drive.google.com/drive/folders/1omeDE_8Anl9IjV-JzRN4es_h_S5ECh-R?usp=drive_link\",\n",
        "        250: \"https://drive.google.com/drive/folders/PASTE_FOLDER_ID\",\n",
        "        300: \"https://drive.google.com/drive/folders/PASTE_FOLDER_ID\",\n",
        "    },\n",
        "    \"2\": {50: \"...\", 100: \"...\", 150: \"...\", 200: \"...\", 250: \"...\", 300: \"...\"},\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading checkpoint folder for 1 / 200 ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing file 1LA89XKMwRCTZqLeacGuU4JSCtxOPMQIH Copy of checkpoint_200.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1LA89XKMwRCTZqLeacGuU4JSCtxOPMQIH\n",
            "From (redirected): https://drive.google.com/uc?id=1LA89XKMwRCTZqLeacGuU4JSCtxOPMQIH&confirm=t&uuid=242b0fee-778f-43a0-835a-7114a02e69ee\n",
            "To: /content/checkpoints/1/Copy of checkpoint_200.pt\n",
            "100%|██████████| 133M/133M [00:01<00:00, 129MB/s]  \n",
            "Download completed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved to /content/checkpoints/1/200/checkpoint_200.pt\n",
            "Available: ['checkpoint_200.pt']\n",
            "Using: /content/checkpoints/1/200/checkpoint_200.pt\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "WORK_DIR = \"/content\" if os.path.exists(\"/content\") else \".\"\n",
        "CHECKPOINTS_ROOT = os.path.join(WORK_DIR, \"checkpoints\")\n",
        "REPOS_DIR = os.path.join(WORK_DIR, \"repos\")\n",
        "CHECKPOINT_NAME = f\"checkpoint_{EPOCH}.pt\"\n",
        "OUTPUT_DIR = os.path.join(WORK_DIR, \"output\")\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "version_dir = os.path.join(CHECKPOINTS_ROOT, VERSION)\n",
        "epoch_dir = os.path.join(version_dir, str(EPOCH))\n",
        "CKPT_PATH = os.path.join(epoch_dir, CHECKPOINT_NAME)\n",
        "if VERSION not in CHECKPOINT_FOLDER_LINKS or EPOCH not in CHECKPOINT_FOLDER_LINKS.get(VERSION, {}):\n",
        "    raise ValueError(f\"No folder link for (VERSION={VERSION}, EPOCH={EPOCH}). Edit CHECKPOINT_FOLDER_LINKS in the cell above.\")\n",
        "folder_url = CHECKPOINT_FOLDER_LINKS[VERSION][EPOCH]\n",
        "if not isinstance(folder_url, str) or \"PASTE_FOLDER\" in folder_url or \"/folders/\" not in folder_url:\n",
        "    raise ValueError(\n",
        "        f\"Invalid folder link for (VERSION={VERSION}, EPOCH={EPOCH}). \"\n",
        "        \"Replace the placeholder in CHECKPOINT_FOLDER_LINKS (cell above) with a Google Drive folder link \"\n",
        "        \"(share: Anyone with the link). Or use EPOCH 50/100 if you have not set links for this epoch yet.\"\n",
        "    )\n",
        "folder_id = folder_url.strip().split(\"/folders/\")[-1].split(\"/\")[0].split(\"?\")[0]\n",
        "\n",
        "need_download = not os.path.isfile(CKPT_PATH)\n",
        "if need_download:\n",
        "    import gdown\n",
        "    import shutil\n",
        "    os.makedirs(version_dir, exist_ok=True)\n",
        "    print(\"Downloading checkpoint folder for\", VERSION, \"/\", EPOCH, \"...\")\n",
        "    gdown.download_folder(id=folder_id, output=version_dir, quiet=False)\n",
        "    src = None\n",
        "    for root, _, files in os.walk(version_dir):\n",
        "        if CHECKPOINT_NAME in files:\n",
        "            src = os.path.join(root, CHECKPOINT_NAME)\n",
        "            break\n",
        "    if not src or not os.path.isfile(src):\n",
        "        raise FileNotFoundError(f\"{CHECKPOINT_NAME} not found in downloaded folder. Ensure the Drive folder contains that file.\")\n",
        "    os.makedirs(epoch_dir, exist_ok=True)\n",
        "    shutil.copy2(src, CKPT_PATH)\n",
        "    print(\"Saved to\", CKPT_PATH)\n",
        "else:\n",
        "    print(\"Checkpoint already on disk:\", CKPT_PATH)\n",
        "\n",
        "CHECKPOINTS_DIR = epoch_dir\n",
        "if os.path.isdir(CHECKPOINTS_DIR):\n",
        "    print(\"Available:\", sorted([f for f in os.listdir(CHECKPOINTS_DIR) if f.endswith(\".pt\")]) or \"(none)\")\n",
        "print(\"Using:\", CKPT_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Install deps and StyleGAN2 repo (GitHub)\n",
        "\n",
        "Clone StyleGAN2 repo from GitHub if not already present. No Drive, no CLIP, no base weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q ftfy regex tqdm gdown Ninja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import sys\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
        "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'none'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SEED = 3456\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "print(f\"Seeds fixed to {SEED}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# StyleGAN2 repo\n",
        "STYLEGAN2_ROOT = os.path.join(REPOS_DIR, \"stylegan2-pytorch\")\n",
        "if not os.path.isfile(os.path.join(STYLEGAN2_ROOT, \"model.py\")):\n",
        "    os.makedirs(REPOS_DIR, exist_ok=True)\n",
        "    print(\"Cloning StyleGAN2 repo...\")\n",
        "    !git clone https://github.com/rosinality/stylegan2-pytorch.git \"{STYLEGAN2_ROOT}\"\n",
        "else:\n",
        "    print(\"StyleGAN2 repo at\", STYLEGAN2_ROOT)\n",
        "sys.path.insert(0, STYLEGAN2_ROOT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inference needs only checkpoint (G_train). No base weights, no CLIP."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Load trained generator\n",
        "\n",
        "Create Generator, load trained weights from checkpoint (key `G_train`). Checkpoint contains full trained generator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from model import Generator\n",
        "\n",
        "latent_dim = 512\n",
        "generator = Generator(size=1024, style_dim=latent_dim, n_mlp=8).to(device)\n",
        "\n",
        "if not os.path.isfile(CKPT_PATH):\n",
        "    raise FileNotFoundError(f\"Checkpoint not found: {CKPT_PATH}. Set VERSION and EPOCH in User settings, then run Step 1 to download.\")\n",
        "with open(CKPT_PATH, \"rb\") as f:\n",
        "    if f.read(100).lstrip().startswith(b\"<\"):\n",
        "        raise RuntimeError(\n",
        "            f\"{CKPT_PATH} is an HTML file (Drive returned a page, not the .pt). \"\n",
        "            \"Re-run Step 1 with a direct download link (https://drive.google.com/uc?id=FILE_ID), or download the .pt manually.\"\n",
        "        )\n",
        "ckpt = torch.load(CKPT_PATH, map_location=device, weights_only=False)\n",
        "generator.load_state_dict(ckpt[\"G_train\"])\n",
        "generator.eval()\n",
        "\n",
        "print(\"Trained generator loaded from\", CKPT_PATH)\n",
        "if \"source\" in ckpt and \"target\" in ckpt:\n",
        "    print(\"  source:\", ckpt.get(\"source\", \"—\"))\n",
        "    print(\"  target:\", ckpt.get(\"target\", \"—\"))\n",
        "    print(\"  iter:\", ckpt.get(\"iter\", \"—\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Generate samples\n",
        "\n",
        "Sample random z, generate images with the trained generator, display."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def to_np(tensor):\n",
        "    \"\"\"Convert (B, 3, H, W) tensor in [-1,1] to numpy for display.\"\"\"\n",
        "    x = (tensor.clamp(-1, 1) + 1) / 2\n",
        "    x = x.permute(0, 2, 3, 1).cpu().numpy()\n",
        "    return x\n",
        "\n",
        "N_SAMPLES = 4  # number of images to generate\n",
        "\n",
        "with torch.no_grad():\n",
        "    z = torch.randn(N_SAMPLES, latent_dim, device=device)\n",
        "    imgs, _ = generator([z], input_is_latent=False)\n",
        "\n",
        "imgs_np = to_np(imgs)\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
        "axes = axes.flatten()\n",
        "for i in range(N_SAMPLES):\n",
        "    axes[i].imshow(imgs_np[i])\n",
        "    axes[i].axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: save generated images\n",
        "from PIL import Image\n",
        "\n",
        "ckpt_basename = os.path.splitext(os.path.basename(CKPT_PATH))[0]\n",
        "for i in range(N_SAMPLES):\n",
        "    arr = (imgs_np[i] * 255).astype(np.uint8)\n",
        "    img = Image.fromarray(arr)\n",
        "    out_path = os.path.join(OUTPUT_DIR, f\"{ckpt_basename}_sample_{i}.png\")\n",
        "    img.save(out_path)\n",
        "    print(\"Saved:\", out_path)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
